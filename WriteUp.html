<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1 plus MathML 2.0//EN" "http://www.w3.org/Math/DTD/mathml2/xhtml-math11-f.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><!--This file was converted to xhtml by LibreOffice - see http://cgit.freedesktop.org/libreoffice/core/tree/filter/source/xslt for the code.--><head profile="http://dublincore.org/documents/dcmi-terms/"><meta http-equiv="Content-Type" content="application/xhtml+xml; charset=utf-8"/><title xml:lang="en-US">- no title specified</title><meta name="DCTERMS.title" content="" xml:lang="en-US"/><meta name="DCTERMS.language" content="en-US" scheme="DCTERMS.RFC4646"/><meta name="DCTERMS.source" content="http://xml.openoffice.org/odf2xhtml"/><meta name="DCTERMS.issued" content="2018-09-14T10:27:01.837976707" scheme="DCTERMS.W3CDTF"/><meta name="DCTERMS.modified" content="2018-09-27T15:31:44.148960183" scheme="DCTERMS.W3CDTF"/><meta name="DCTERMS.provenance" content="" xml:lang="en-US"/><meta name="DCTERMS.subject" content="," xml:lang="en-US"/><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/" hreflang="en"/><link rel="schema.DCTERMS" href="http://purl.org/dc/terms/" hreflang="en"/><link rel="schema.DCTYPE" href="http://purl.org/dc/dcmitype/" hreflang="en"/><link rel="schema.DCAM" href="http://purl.org/dc/dcam/" hreflang="en"/><style type="text/css">
	@page {  }
	table { border-collapse:collapse; border-spacing:0; empty-cells:show }
	td, th { vertical-align:top; font-size:12pt;}
	h1, h2, h3, h4, h5, h6 { clear:both }
	ol, ul { margin:0; padding:0;}
	li { list-style: none; margin:0; padding:0;}
	<!-- "li span.odfLiEnd" - IE 7 issue-->
	li span. { clear: both; line-height:0; width:0; height:0; margin:0; padding:0; }
	span.footnodeNumber { padding-right:1em; }
	span.annotation_style_by_filter { font-size:95%; font-family:Arial; background-color:#fff000;  margin:0; border:0; padding:0;  }
	* { margin:0;}
	.Heading_20_1 { font-size:130%; margin-bottom:0.212cm; margin-top:0.423cm; font-family:Liberation Sans; writing-mode:page; margin-left:0cm; margin-right:0cm; text-indent:0cm; font-weight:bold; }
	.Heading_20_2 { font-size:115%; margin-bottom:0.212cm; margin-top:0.353cm; font-family:Liberation Sans; writing-mode:page; margin-left:0cm; margin-right:0cm; text-indent:0cm; font-weight:bold; }
	.P1 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P10 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P100 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P101 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P102 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P103 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; font-style:italic; }
	.P104 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P105 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P106 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P107 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P108 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P11 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P110 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P111 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P113 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; font-weight:bold; }
	.P12 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P13 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P14 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P15 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P16 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P17 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P18 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P19 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P2 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P20 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P21 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P22 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P23 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P24 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P25 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P26 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P27 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P28 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P29 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P3 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P30 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P31 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P32 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P33 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P34 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P35 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P36 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P37 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P38 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P39 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P4 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P40 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P41 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P42 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P43 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P44 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P45 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P46 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P47 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P48 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P49 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P5 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P50 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P51 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P52 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P53 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P54 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P55 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P56 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P57 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P58 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P6 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P60 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P61 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P62 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P63 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P66 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P67 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P68 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P69 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P7 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P71 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P72 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P73 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P74 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P75 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P76 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P78 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P8 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P80 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P81 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P82 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P83 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P84 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P85 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P86 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P87 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P88 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; text-decoration:underline; }
	.P89 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; text-decoration:underline; }
	.P9 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P91 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P93 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P94 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.P96 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; font-weight:bold; }
	.P97 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; font-weight:bold; }
	.P98 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; font-weight:bold; }
	.P99 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; }
	.Preformatted_20_Text { font-size:10pt; font-family:Liberation Mono; writing-mode:page; margin-top:0cm; margin-bottom:0cm; }
	.Table2 { width:17cm; float:none; }
	.Table2_A1 { padding:0.097cm; border-width:thin; border-style:solid; border-color:#000000; }
	.Table2_A2 { padding:0.097cm; border-left-width:thin; border-left-style:solid; border-left-color:#000000; border-right-width:thin; border-right-style:solid; border-right-color:#000000; border-top-style:none; border-bottom-width:thin; border-bottom-style:solid; border-bottom-color:#000000; }
	.Table2_A { width:17cm; }
	.Bullet_20_Symbols { font-family:OpenSymbol; }
	.Internet_20_link { color:#000080; text-decoration:underline; }
	.T100 { text-decoration:underline; }
	.T102 { font-style:italic; }
	.T103 { font-style:italic; }
	.T104 { font-style:italic; }
	.T105 { font-style:italic; }
	.T91 { font-weight:bold; }
	.T92 { font-weight:bold; }
	.T93 { font-weight:bold; }
	.T94 { font-weight:bold; }
	.T95 { font-weight:bold; }
	.T96 { font-weight:bold; }
	.T98 { text-decoration:underline; }
	.T99 { text-decoration:underline; }
	<!-- ODF styles with no properties representable as CSS -->
	.Endnote_20_Symbol .Footnote_20_Symbol .T1 .T10 .T101 .T106 .T107 .T108 .T109 .T11 .T12 .T13 .T14 .T15 .T16 .T17 .T18 .T19 .T2 .T20 .T21 .T22 .T23 .T24 .T25 .T26 .T27 .T28 .T29 .T3 .T30 .T31 .T32 .T33 .T34 .T35 .T36 .T37 .T38 .T39 .T4 .T40 .T41 .T42 .T43 .T44 .T45 .T46 .T47 .T48 .T49 .T5 .T50 .T51 .T52 .T53 .T54 .T55 .T56 .T57 .T58 .T59 .T6 .T60 .T61 .T62 .T63 .T64 .T65 .T66 .T67 .T68 .T69 .T7 .T70 .T71 .T72 .T73 .T74 .T75 .T76 .T77 .T78 .T79 .T8 .T80 .T81 .T82 .T83 .T84 .T85 .T86 .T87 .T88 .T89 .T9 .T90  { }
	</style></head><body dir="ltr" style="max-width:21.001cm;margin-top:2cm; margin-bottom:2cm; margin-left:2cm; margin-right:2cm; "><h1 class="Heading_20_1"><a id="a__Overview"><span/></a>Overview</h1><p class="P1"> </p><p class="P1">For any business <span class="T16">that </span>sell<span class="T16">s</span> services to consumers, two key <span class="T1">forecasting </span>questions are:</p><p class="P1"> </p><ul><li><p class="P78" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span>Which consumers<span class="T1"> </span>are likely to <span class="T91">cancel or downgrade</span> their service?<span class="odfLiEnd"/> </p></li><li><p class="P78" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span>Which consumers<span class="T1"> are likely to </span><span class="T92">upgrade</span><span class="T1"> their service?</span><span class="odfLiEnd"/> </p></li></ul><p class="P3"> </p><p class="P4">For the former (the <span class="T2">potential </span>‘downgraders’), the business may <span class="T69">wish to </span>preemptively <span class="T41">avoid the scenario by</span> offer<span class="T41">ing</span> an alternative service package that’s more suited to <span class="T41">the consumer’s </span>needs.</p><p class="P3"> </p><p class="P58">For the latter (the <span class="T2">potential </span>’upgraders’), the business may wish to <span class="T41">maximise consumer revenue</span> <span class="T41">by </span>preemptively <span class="T41">selling an upgraded service package </span>or even upsell<span class="T41">ing</span> additional services.</p><p class="P1"> </p><p class="P6">So it’s clear that early identification of potential downgraders/upgraders can offer significant business benefits, both in <span class="T3">terms of reducing consumer ‘churn’ and maximising business revenue.</span></p><p class="P5"> </p><p class="P8"><span class="T6">For m</span>obile <span class="T4">p</span>hone <span class="T10">operators</span>, <span class="T6">it’s typically very simple for a subscriber to downgrade their phone plan or even to cancel and switch to another operator. Consequently, downgrades and churn are significant issues.</span></p><p class="P7"> </p><p class="P11">On the other hand, mobile phone operators typically offer a wide range of plans and services, so maximising upgrade and upsell of these plans/services can <span class="T42">offer significant revenue benefits</span>.</p><p class="P7"> </p><p class="P10">Machine Learning <span class="T23">potentially </span>offers a means of <span class="T23">using subscriber data to </span>predict <span class="T5">who will downgrade/cancel or upgrade. In Machine Learning terminology, this is a classification task.</span></p><p class="P10"> </p><p class="P24">For mobile phone operators, however, stringent data privacy controls and ph<span class="T43">ys</span>ical dispersal of data (across multiple subsystems or even locations) <span class="T42">often </span>means that a comprehensive, ‘wide’ set of subscriber data is not readily available for machine learning classification.</p><p class="P9"> </p><p class="P13"><span class="T9">Thus, t</span>he rest of this <span class="T42">write-up</span> describes a <span class="T7">prototype</span> t<span class="T8">hat seeks to</span> <span class="T7">predict downgrades/upgrades from a very reduced (‘narrow’) set of subscriber data; i.e., with key items (features):</span></p><p class="P13"> </p><ul><li><p class="P80" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span><span class="T13">prepaid or postpaid</span><span class="odfLiEnd"/> </p></li><li><p class="P82" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span>contract length (for postpaid)<span class="odfLiEnd"/> </p></li><li><p class="P82" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span>subscriber spend<span class="odfLiEnd"/> </p></li><li><p class="P81" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span><span class="T12">number of calls per month</span><span class="odfLiEnd"/> </p></li><li><p class="P83" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span>purchased versus used calls/texts/data per month<span class="odfLiEnd"/> </p></li></ul><p class="P13"> </p><p class="P25">The above data is quite anonymous (thus less privacy-sensitive) and should be quite readily available, e.g., from the mobile phone operator’s billing system and <span class="T44">associated</span> subsystems.</p><p class="P12"> </p><p class="P26">The prototype <span class="T70">seeks to </span>leverage the fact that a lot of important information relevant to downgrade/upgrade prediction can be <span class="T91">inferred</span> from the aforementioned data items; for example:</p><p class="P14"> </p><ul><li><p class="P84" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span><span class="T15">Is the subscriber ‘steady’ (long postpaid contract) or more ‘fickle’ (short postpaid contract or prepaid)?</span><span class="odfLiEnd"/> </p></li><li><p class="P84" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span><span class="T11">Is the subscriber quite spendthrift (high spend and purchases much more calls/texts/data than they actually use) or a more careful spender (low spend and only purchases what they need)?</span><span class="odfLiEnd"/> </p></li><li><p class="P86" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span>Is the subscriber <span class="T18">using almost the maximum of their purchased levels of calls/text/data? This may suggest they’re likely to upgrade.</span><span class="odfLiEnd"/> </p></li><li><p class="P85" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span><span class="T14">What age is the subscriber? This can be roughly inferred from usage patterns; e.g., younger subscribers tend to use more data and less calls/texts than older subscribers. Younger subscribers may also be more ‘fickle’; i.e., more likely to switch operators.</span><span class="odfLiEnd"/> </p></li><li><p class="P85" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span><span class="T14">Is the subscriber a business, thus more likely to regularly review/audit their spend? This can be roughly inferred from a high number of short calls and high data usage.</span><span class="odfLiEnd"/> </p></li></ul><p class="P14"> </p><h1 class="Heading_20_1"><a id="a__Data_Preparation"><span/></a>Data Preparation</h1><p class="P1"> </p><p class="P15">For th<span class="T22">is</span> prototype, <span class="T17">a </span><span class="T98">synthetic</span><span class="T17"> subscriber data set was created using the following steps:</span></p><p class="P15"> </p><p class="P41"><span class="T91">1)</span> <span class="T19">Generate the initial random data set using </span><a href="http://generatedata.com/" class="Internet_20_link"><span class="T19">http://generatedata.com/</span></a><span class="T19"> . The script was run locally to avail of an increased data set limit of 100,000 items. Generation was run 10 times to produce a data set with a total of 1,000,000 subscribers. This data set is available at </span><a href="https://github.com/Peter-Martin/mobile-subscribers/blob/master/prepare-data/all-original.csv.tar.gz" class="Internet_20_link"><span class="T19">https://github.com/Peter-Martin/mobile-subscribers/blob/master/prepare-data/all-original.csv.tar.gz</span></a></p><p class="P41"> </p><p class="P41"><span class="T91">2)</span> <span class="T21">Clean the initial data set to fix and/or remove any invalid values. A custom Groovy script was written to perform the cleaning. This script is available at </span><a href="https://github.com/Peter-Martin/mobile-subscribers/blob/master/prepare-data/src/Clean.groovy" class="Internet_20_link"><span class="T21">https://github.com/Peter-Martin/mobile-subscribers/blob/master/prepare-data/src/Clean.groovy</span></a></p><p class="P16"> </p><p class="P16"><span class="T91">3)</span> <span class="T21">Label the data set; i.e., classify each subscriber as cancelled/downgraded/unchanged/upgraded </span>according to <span class="T21">the rules/inferences listed towards the end of the earlier ‘Overview’ section. &lt;&lt;&lt; Link &gt;&gt;&gt;. Note, however, that an element of real-world randomness was also included; e.g., so that a small number of apparently more ‘stable’ subscribers still downgrade or cancel, etc.</span></p><p class="P42">An additional Groovy script was written to perform this labelling; <span class="T64">this is available at </span><a href="https://github.com/Peter-Martin/mobile-subscribers/blob/master/prepare-data/src/Label.groovy" class="Internet_20_link"><span class="T64">https://github.com/Peter-Martin/mobile-subscribers/blob/master/prepare-data/src/Label.groovy</span></a></p><p class="P44"> </p><p class="P44"><span class="T68">The original full dataset is available at </span><a href="https://github.com/Peter-Martin/mobile-subscribers/blob/master/prepare-data/all-labelled.csv.tar.gz" class="Internet_20_link"><span class="T68">https://github.com/Peter-Martin/mobile-subscribers/blob/master/prepare-data/all-labelled.csv.tar.gz</span></a><span class="T68">. The set of original labels and their values is as follows:</span></p><p class="P43"> </p><table border="0" cellspacing="0" cellpadding="0" class="Table2"><colgroup><col width="743"/></colgroup><tr><td style="text-align:left;width:17cm; " class="Table2_A1"><p class="P113">UpdatedIn90Days</p><p class="P51"> </p><p class="P52">The subscriber’s action within 90 days of the data sampling:</p><p class="P52"> </p><ul><li><p class="P110" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span>upgraded plan                (for prepaid, means switched to postpaid)<span class="odfLiEnd"/> </p></li><li><p class="P110" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span>unchanged<span class="odfLiEnd"/> </p></li><li><p class="P110" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span>downgraded plan        (postpaid only)<span class="odfLiEnd"/> </p></li><li><p class="P110" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span>switched to prepaid        (postpaid only)<span class="odfLiEnd"/> </p></li><li><p class="P110" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span>cancelled                (prepaid stopped topups, postpaid cancelled contract)<span class="odfLiEnd"/> </p></li></ul><p class="P54"> </p><p class="P54"><span class="T66">Note that some of the prototype iterations simplified the above label set; this is described further down.</span> </p></td></tr><tr><td style="text-align:left;width:17cm; " class="Table2_A2"><p class="P113">PurchasedAdditionalIn90Days</p><p class="P51"> </p><p class="P52">Whether or not the subscriber purchased additional products (from the mobile operator) within 90 days of the data sampling:</p><p class="P52"> </p><ul><li><p class="P111" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span>purchased additional products<span class="odfLiEnd"/> </p></li><li><p class="P111" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span>didn't purchase additional products<span class="odfLiEnd"/> </p></li></ul><p class="P52"> </p><p class="P53"><span class="T91">NB:</span> <span class="T65">This label was generated in the original dataset. However, in order to narrow its focus, the prototype didn’t attempt to predict this label value.</span></p></td></tr></table><p class="P45"> </p><p class="P17"><span class="T91">4)</span> <span class="T20">Split the labelled dataset into training (60%), validation (20%) and test (20%) sets. See </span><a href="https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7" class="Internet_20_link"><span class="T20">https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7</span></a><span class="T20"> for an explanation of the purpose of each of these sets.</span></p><p class="P1"> </p><h1 class="Heading_20_1"><a id="a__Software_Evaluation"><span/></a>Software Evaluation</h1><p class="P1"> </p><p class="P18">There are many open-source and commercial software tools and packages available for Machine Learning. Some of the more widely-used packages were evaluated <span class="T57">for</span> <span class="T24">this prototype:</span></p><p class="P18"> </p><p class="P88"><span class="T24">TensorFlow</span></p><p class="P87"><span class="T24">Widely-used Python-based machine learning framework. Using TensorFlow’s full functionality requires quite a strong proficiency in Python. While bindings for Java (using JNI) and JavaScript are available, these don’t support all of the functionality of the Python API. </span><a href="https://www.tensorflow.org/" class="Internet_20_link"><span class="T24">https://www.tensorflow.org/</span></a></p><p class="P87"> </p><p class="P88"><span class="T25">scikit-learn</span></p><p class="P87"><span class="T25">Also Python-based, but simpler to use than TensorFlow. Consequently, it’s suitable for use by developers with less proficiency in Python. </span><a href="http://scikit-learn.org/stable/" class="Internet_20_link"><span class="T25">http://scikit-learn.org/stable/</span></a></p><p class="P87"> </p><p class="P88"><span class="T24">H2O AI</span></p><p class="P87"><span class="T24">Also Python and R-based. One of H2O’s advantages is that it includes a browser-based UI (‘Flow’) that provides a very convenient way of loading data and training an initial machine learning model. </span><a href="https://www.h2o.ai/" class="Internet_20_link"><span class="T24">https://www.h2o.ai/</span></a></p><p class="P19"> </p><p class="P27">TensorFlow was used for the initial machine learning prototyping. However, b<span class="T25">ased on the above evaluation, scikit-learn was </span>subsequently <span class="T25">used for all of the prototyping.</span></p><p class="P27"> </p><p class="P28"><span class="T50">Note that, f</span>or machine-learning production environments, the choice of software should be re-evaluated. The following factors, among others, <span class="T32">would need to be evaluated </span>for the above software tools/packages:</p><p class="P28"> </p><ul><li><p class="P91" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span><span class="T40">P</span>erformance, <span class="T83">including usage of GPUs ,etc.</span><span class="odfLiEnd"/> </p></li><li><p class="P91" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span>Cloud availability.<span class="odfLiEnd"/> </p></li><li><p class="P91" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span>Clustering <span class="T33">cap</span>ability.<span class="odfLiEnd"/> </p></li><li><p class="P91" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span><span class="T39">Integration with pipeline (e.g., Apache Spark) that feeds data to the machine learning model.</span><span class="odfLiEnd"/> </p></li></ul><p class="P28"> </p><h1 class="Heading_20_1"><a id="a__Model_Training_and_Prediction"><span/></a>Model Training <span class="T29">and Prediction</span></h1><p class="P1"> </p><p class="P20">A number of different <span class="T31">iterations</span> were performed during model training. <span class="T46">Each</span> <span class="T45">iteration trained a new model by incrementally varying the classifiers and/or applying various transformations to the input data:</span></p><p class="P20"> </p><h2 class="Heading_20_2"><a id="a__Classifiers"><span/></a>Classifiers</h2><p class="P30"> </p><p class="P46">The following classifiers were used during the training iterations:</p><p class="P46"> </p><ul><li><p class="P107" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span><span class="T91">Multi-layer Perceptron Classifier</span> based on neural networks. <a href="http://scikit-learn.org/stable/modules/neural_networks_supervised.html" class="Internet_20_link"><span class="T67">http://scikit-learn.org/stable/modules/neural_networks_supervised.html</span></a><span class="odfLiEnd"/> </p></li><li><p class="P107" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span><span class="T91">Random Forest Classifier</span> <span class="T56">based on decision trees. </span><a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" class="Internet_20_link"><span class="T56">http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html</span></a><span class="odfLiEnd"/> </p></li><li><p class="P107" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span><span class="T96">Gradient Boosting Classifier</span><span class="T56"> based on an ensemble of decision trees. </span><a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html" class="Internet_20_link"><span class="T56">http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html</span></a><span class="odfLiEnd"/> </p></li><li><p class="P107" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span><span class="T96">Stochastic Gradient Descent Classifier</span><span class="T56"> based on iteratively reducing the loss/error/cost associated with a model. </span><a href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html" class="Internet_20_link"><span class="T56">http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html</span></a><span class="odfLiEnd"/> </p></li><li><p class="P107" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span><span class="T96">Linear Support Vector Classifier</span><span class="T56"> based on categorising examples. </span><a href="http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html" class="Internet_20_link"><span class="T56">http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html</span></a><span class="odfLiEnd"/> </p></li></ul><p class="P40"> </p><p class="P37">Note that each training iteration used an identically-configured classifier <span class="T55">(same random state, same number of hidden layers for neural network, etc.)</span>. It may be possible to obtain improved prediction results by varying the <span class="T71">configuration of each </span>classifier..</p><p class="P30"> </p><h2 class="Heading_20_2"><a id="a__Data_Sets"><span/></a>Data Sets</h2><p class="P32"> </p><p class="P46">The following subscriber datasets were used during the training iterations:</p><p class="P46"> </p><p class="P89">Full</p><p class="P93"><span class="T58">Includes all of the upgrade and downgrade classes/labels as described earlier. Includes both postpaid and prepaid subscribers. The full dataset (training, validation and test) is available at </span><a href="https://github.com/Peter-Martin/mobile-subscribers/tree/master/prepare-data/one-label" class="Internet_20_link"><span class="T58">https://github.com/Peter-Martin/mobile-subscribers/tree/master/prepare-data/one-label</span></a></p><p class="P93"> </p><p class="P89">Simple</p><p class="P93"><span class="T58">Generated by reducing the multiple downgrade labels (described for the full dataset above) to a single ‘downgrade’ label that represents any of cancelled, switched to prepaid or the original downgraded label. The simple downgrade dataset (training, validation and test) is available at </span><a href="https://github.com/Peter-Martin/mobile-subscribers/tree/master/prepare-data/one-label/simple" class="Internet_20_link"><span class="T58">https://github.com/Peter-Martin/mobile-subscribers/tree/master/prepare-data/one-label/simple</span></a></p><p class="P94"> </p><p class="P89">Simple Downgrade</p><p class="P93"><span class="T58">Generated by removing the upgrade label from the above simple dataset. The simple downgrade dataset (training, validation and test) is available at </span><a href="https://github.com/Peter-Martin/mobile-subscribers/tree/master/prepare-data/one-label/simple/downgrade" class="Internet_20_link"><span class="T58">https://github.com/Peter-Martin/mobile-subscribers/tree/master/prepare-data/one-label/simple/downgrade</span></a></p><p class="P94"> </p><p class="P89">Simple Downgrade Postpaid</p><p class="P93"><span class="T58">Generated by removing the prepaid subscribers from the above simple downgrade dataset; i.e., so that only postpaid subscribers remain. The simple downgrade postpaid dataset (training, validation and test) is available at </span><a href="https://github.com/Peter-Martin/mobile-subscribers/tree/master/prepare-data/one-label/simple/downgrade/postpaid" class="Internet_20_link"><span class="T58">https://github.com/Peter-Martin/mobile-subscribers/tree/master/prepare-data/one-label/simple/downgrade/postpaid</span></a></p><p class="P31"> </p><h2 class="Heading_20_2"><a id="a__Additional_Transformations"><span/></a>Additional Transformations</h2><p class="P32"> </p><p class="P46">During training iterations, the following transformations were applied to the datasets described above:</p><ul><li><p class="P61" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span><span class="T91">Feature Scaling</span> to normalize feature values; <span class="T59">i.e., so that all feature values are within a similar range.</span><span class="odfLiEnd"/> </p></li><li><p class="P62" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span><span class="T93">Oversampling</span><span class="T83"> (using </span>SMOTE<span class="T83">) </span>to <span class="T34">balance</span> the relative distribution of the various classes (labels); <span class="T60">i.e., so that there are fairly similar numbers of subscribers that downgrade, upgrade, stay unchanged, etc.</span><span class="odfLiEnd"/> </p></li></ul><p class="P60"> </p><p class="P35"><span class="T48">Note that s</span>ome classifiers are <span class="T49">more </span>sensitive <span class="T49">than others to the above transformations.</span></p><p class="P35"> </p><p class="P38"><span class="T83">Also n</span>ote that validation wasn’t <span class="T88">explicitly/externally </span>applied while performing training iterations; <span class="T88">some of the earlier classifiers internally apply nested k-fold cross-validation.</span></p><p class="P21"> </p><p class="P32">The following metrics were applied <span class="T52">in order </span>to <span class="T51">score each iteration’s </span>predictions:</p><p class="P32"> </p><ul><li><p class="P55" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span><span class="T91">Precision:</span> <span class="T61">Reflects the prediction ‘q</span>uality’ <span class="T61">of the model; this figure is</span> higher <span class="T61">for </span>less false positives.<span class="odfLiEnd"/> </p></li><li><p class="P55" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span><span class="T91">Recall:</span> <span class="T61">Reflects the prediction ‘q</span>uantity’ <span class="T61">achieved by the model; the figure is </span>higher with more true positives.<span class="odfLiEnd"/> </p></li><li><p class="P63" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span><span class="T91">F1 Score:</span> Combines the precision and recall so they can be compared across <span class="T54">the various training iterations. </span>The F1 score is defined as 2(Precision*Recall) / (Precision+Recall)<span class="odfLiEnd"/> </p></li></ul><p class="P20"> </p><p class="P34"><span class="T47">In order to compare like-for-like metrics across iterations</span>, the metrics <span class="T54">above </span>were rolled-up to only cover the simple downgrade true/false scenario. That scenario applies across all of the data sets mentioned earlier, <span class="T47">it’s thus available for comparison all </span>iterations. <span class="T53">So, when taking prediction metrics for the full data set, the cancelled/switched-to-prepaid/downgraded classes were all simply counted as ‘downgraded’.</span></p><p class="P33"> </p><p class="P39">Note that similar metrics could have been <span class="T79">measured </span>for predicting upgrade scenarios; <span class="T80">this could be achieved with the following simple changes:</span></p><p class="P39"> </p><p class="P56"><span class="T94">i)</span><span class="T101"> </span>Use the ‘Simple Upgrade’ and ‘Simple Upgrade Postpaid’ datasets instead of their downgrade equivalents.</p><p class="P39"><span class="T94">ii)</span><span class="T101"> Take prediction metrics (precision and recall) for upgrade instead of for downgrade</span>.</p><p class="P20"> </p><p class="P50">The Python source code for the training model iterations is available at <a href="https://github.com/Peter-Martin/mobile-subscribers/blob/master/train-model/scikit-learn/manual-sklearn.py" class="Internet_20_link">https://github.com/Peter-Martin/mobile-subscribers/blob/master/train-model/scikit-learn/</a><a href="https://github.com/Peter-Martin/mobile-subscribers/blob/master/train-model/scikit-learn/manual-sklearn.py" class="Internet_20_link"><span class="T81">iterate</span></a><a href="https://github.com/Peter-Martin/mobile-subscribers/blob/master/train-model/scikit-learn/manual-sklearn.py" class="Internet_20_link">.py</a></p><p class="P23"> </p><h1 class="Heading_20_1"><a id="a__Results_and_Analysis"><span/></a>Results and Analysis</h1><p class="P23"> </p><p class="P23">The following table describes the training iterations and their resulting prediction metrics; <span class="T72">the iterations are sorted by their F1 scores. Note that t</span>he table excludes any iterations that didn’t complete or that failed to predict some classes/<span class="T82">labels</span>.</p><p class="P47"> </p><p class="P108">&lt;&lt;&lt;TODO&gt;&gt;&gt;</p><p class="P47"> </p><p class="P47">The confusion matrices for the top <span class="T85">2</span> performers <span class="T73">(by F1 score) </span>are as follo<span class="T75">w</span>s; <span class="T75">the matrices respectively show the metrics for </span><span class="T103">downgraded</span><span class="T75"> and </span><span class="T103">unchanged</span><span class="T75"> labels.</span></p><p class="P47"> </p><p class="P96"><span class="T75">i) </span>Simple Downgrade Postpaid <span class="T78">dataset | </span>M<span class="T73">ulti-layer Perceptron</span> <span class="T73">classifier</span></p><p class="P96"><span class="T73">scaled | oversampled</span></p><p class="P96"> </p><p class="Preformatted_20_Text">[[15069 11039]</p><p class="Preformatted_20_Text"> [16726 55680]]</p><p class="Preformatted_20_Text"> </p><p class="P67"><span class="T86">For predicting downgrades, this model iteration produced </span>15,069 true positives; <span class="T86">i.e., subscribers successfully predicted as downgrades</span>. <span class="T87">However, the model failed to predict 11,039 downgrades, t</span>hus it has a recall (‘quantity’) score of 0.58.</p><p class="P68"> </p><p class="P68">In addition, the model produced 16,726 false positives; i.e., erroneously predicted subscribers as downgraded when they were actually unchanged. This is from the total unchanged figure of (16,726 + 55,680). Thus, the model has a reasonable <span class="T77">precision (‘quality’) score of 0.47.</span></p><p class="P47"> </p><p class="P96"><span class="T85">ii) </span>Simple Downgrade Postpaid <span class="T78">dataset | Stochastic Gradient Descent classifier</span></p><p class="P96"><span class="T78">scaled | oversampled</span></p><p class="P96"> </p><p class="Preformatted_20_Text">[[16069 10039]</p><p class="Preformatted_20_Text"> [21660 50746]]</p><p class="Preformatted_20_Text"> </p><p class="P49">This model iteration scored similarly to the previous model; slightly better recall <span class="T77">(‘quantity’) </span>score of 0.61, but a slightly lower precision <span class="T77">(‘quality’) </span>score of 0.43.</p><p class="P49"> </p><p class="P68">It’s also useful to examine a very different confusion matrix for another model iteration:</p><p class="P68"> </p><p class="P96"><span class="T109">iii) </span>Simple Downgrade Postpaid <span class="T78">dataset | </span>M<span class="T73">ulti-layer Perceptron</span> <span class="T73">classifier</span></p><p class="P96">no<span class="T73">t scaled | oversampled</span></p><p class="P96"> </p><p class="Preformatted_20_Text">[[22156  3952]</p><p class="Preformatted_20_Text"> [51695 20711]]</p><p class="Preformatted_20_Text"> </p><p class="P66">For predicting downgrades, this model <span class="T74">iteration produced </span>22,156 true positives; <span class="T74">i.e., subscribers successfully predicted as downgrades.</span> <span class="T74">The model </span>only fail<span class="T74">ed</span> to predict 3,952 <span class="T74">downgraded subscribers</span>. So it has a high recall (‘<span class="T76">quantity’</span>) score <span class="T75">of 0.85.</span></p><p class="P66"> </p><p class="P66">However, the model produced 51,695 false positives; i.e., <span class="T74">erroneously predicted subscribers as downgraded when they were actually unchanged. This is from the total unchanged figure of (51,695 + 20,711). So the model has a low precision (‘quality’) score of 0.30.</span></p><p class="P66"> </p><p class="P69">For the above model iterations, the precision and recall could be fine-tuned by adjusting the <span class="T102">probability threshold</span> (aka <span class="T102">decision threshold</span>); i.e., the point at which a subscriber is adjudged to be either downgraded or unchanged. This is described for scikit-learn in the following article: <a href="https://towardsdatascience.com/fine-tuning-a-classifier-in-scikit-learn-66e048c21e65" class="Internet_20_link">https://towardsdatascience.com/fine-tuning-a-classifier-in-scikit-learn-66e048c21e65</a></p><p class="P69"> </p><p class="P73"><span class="T89">An additional tuning measure would be to use </span>the validation datasets (created at the same time as the training datasets <span class="T89">earlier</span>) to explicitly perform validation. <span class="T89">This could be used to identify any potential </span><span class="T104">underfitting (high bias)</span><span class="T89"> or </span><span class="T104">overfitting (high variance)</span><span class="T89"> by the various model iterations:</span></p><p class="P73"> </p><ul><li><p class="P74" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span><span class="T95">Underfitting</span><span class="T106"> is represented by high error in both training and validation sets. This may be addressed by increasing the number of subscriber features in the datasets; e.g., age, gender, etc.</span><span class="odfLiEnd"/> </p></li><li><p class="P74" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span><span class="T95">Overfitting</span><span class="T106"> is represented by low error in training set, but high error in validation set. This may be addressed by reducing the number of subscriber features or by obtaining data from a greater number of subscribers.</span><span class="odfLiEnd"/> </p></li></ul><p class="P75"> </p><p class="P76">Applying non-nested (cross-) validation is described for scikit-learn at <a href="http://scikit-learn.org/stable/modules/cross_validation.html" class="Internet_20_link">http://scikit-learn.org/stable/modules/cross_validation.html</a></p><p class="P49"> </p><p class="P50"><span class="T91">Note:</span> Automatic machine learning (using scikit-learn) was also evaluated during the course of this prototype. However, it produced a less successful model (lower precision and recall) than the models produced iteratively above. The source code for the automatic machine learning is available at <a href="https://github.com/Peter-Martin/mobile-subscribers/blob/master/train-model/scikit-learn/auto-sklearn.py" class="Internet_20_link">https://github.com/Peter-Martin/mobile-subscribers/blob/master/train-model/scikit-learn/auto-sklearn.py</a></p><p class="P48"> </p><h1 class="Heading_20_1"><a id="a__Conclusions"><span/></a>Conclusions</h1><p class="P1"> </p><p class="P97"><span class="T28">1)</span> Simple and Specific</p><p class="P29"> </p><ul><li><p class="P101" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span>Employing scaling/over-sampling typically delivered small incremental metric improvements; e.g., of a few percent.<span class="odfLiEnd"/> </p></li><li><p class="P102" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span><span class="T35">G</span>reater improvements were observed <span class="T36">by manipulating/engineering the data; e.g., separating unrelated data (postpaid from prepaid), reducing the number of classes/labels, etc.</span><span class="odfLiEnd"/> </p></li><li><p class="P100" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span><span class="T84">The b</span>est results <span class="T84">were achieved </span>when <span class="T84">the </span>number of classes was simplified to downgraded/unchanged/upgraded and <span class="T107">when </span>postpaid <span class="T107">subscribers were </span>separated from prepaid; <span class="T107">i.e., when there was </span>less ‘noise’ in the input data.<span class="odfLiEnd"/> </p></li></ul><p class="P36"> </p><p class="P99"><span class="T106">This conclusion may be stated as follows:</span></p><p class="P99"> </p><p class="P103"><span class="T106">For machine learning classification, </span>ask <span class="T108">a </span><span class="T99">simple</span><span class="T108"> </span>question, then provide <span class="T27">very </span><span class="T100">specific</span><span class="T27"> data to allow that question to be answered.</span></p><p class="P1"> </p><p class="P98">2) Improving Prediction Rates</p><p class="P2"> </p><p class="P57">As-is, the downgrade prediction metrics shown in the earlier table wouldn’t be sufficient for a real-life production environment. However, the following steps could be taken to improve the prediction rate: </p><p class="P2"> </p><ul><li><p class="P104" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span>Use real data; <span class="T62">the synthetic data (generated specifically for this prototype) applies its own rules/inferences, so it has some inbuilt biases.</span><span class="odfLiEnd"/> </p></li><li><p class="P105" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span>Include additional <span class="T38">subscriber </span>features; e.g., age, gender, personal/business, customer <span class="T30">loyalty (period of time with the operator)</span>, etc.<span class="odfLiEnd"/> </p></li><li><p class="P104" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span>Include <span class="T26">comprehensive </span>feature engineering; <a href="https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/" class="Internet_20_link">https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/</a><span class="odfLiEnd"/> </p></li><li><p class="P106" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0.635cm;">•</span><span class="T38">Include mobile operator metrics/features captured at the time of subscriber downgrade/upgrade; average customer review, customer care responsiveness, etc.</span><span class="odfLiEnd"/> </p></li></ul><p class="P22"> </p><p class="P71">Overall, the greater ‘return’ for effort was found from <span class="T63">manipulating and improving</span> the input data, rather than adjusting the classifier algorithms and parameters. This <span class="T37">is where most future efforts should be concentrated.</span></p><p class="P71"> </p><p class="P72"><span class="T90">This reinforces what Andrew Ng states in his Stanford University Machine Learning course notes for </span><a href="https://www.coursera.org/learn/machine-learning" class="Internet_20_link"><span class="T90">https://www.coursera.org/learn/machine-learning</span></a><span class="T90">:</span></p><p class="P72"> </p><p class="P72"><span class="T105">“It’s not who has the best algorithm that wins. It’s who has the most data.”</span></p><p class="P72"><span class="T90">(Banko and Brill, 2001)</span></p></body></html>